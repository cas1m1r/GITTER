======================: FILES :======================
botnet-dga-classifier
├── config
│   └── global.dcf
├── data
│   └── dds-malicious-domains.csv
├── lib
│   ├── data-exists.R
│   ├── dictionary-words.R
│   ├── download-file.R
│   ├── expect-close.R
│   ├── extract-domain.R
│   ├── extract-tld.R
│   ├── helpers.R
│   ├── nin.R
│   └── train-classifier.R
├── munge
│   ├── 00-init.R
│   ├── 01-alexa.R
│   ├── 02-opendns-top.R
│   ├── 03-opendns-random.R
│   ├── 04-quantcast.R
│   ├── 05-data-driven-security.R
│   ├── 06-valid-tlds.R
│   ├── 07-domains.R
│   ├── 08-domain-length.R
│   └── 09-dictionary-words.R
├── README.md
├── reports
│   ├── classify-domains.html
│   ├── classify-domains.Rmd
│   ├── explore-domains.html
│   └── explore-domains.Rmd
└── tests
    ├── data-exists-tests.R
    ├── dictionary-words-tests.R
    ├── extract-domain-tests.R
    ├── extract-tld-tests.R
    └── nin-tests.R

6 directories, 31 files
======================: README CONTENT :======================
Botnet Domain Generation Algorithm Classifier
===================================================================

### Getting Started

The project is managed with [Project Template](http://projecttemplate.net/).  To get directly to the fun of modeling DGA-generated domains, run the following commands which will download, clean, and pre-process all of the required source data.

```
library (ProjectTemplate)
load.project ()
```

This will generate a data set called ```domains``` that is ready for modeling.  This data set contains a ```host``` column identifying a domain name along with a ```type``` column indicating whether that domain is legitimate or was generated by a DGA from a known Botnet.

```
str (domains)
```

Subsequent modeling and analysis based on this modeling data set can be found in the ```reports``` folder.

### Background

The creation of Botnets is an illegal activity that is widely practiced by cyber criminals around the world. A Botnet is a network of compromised computers that have been illegally co-opted and is under the control of a cyber criminal.  Botnets are formed by compromising individual computers, known as Bots, by subvertly installing some form of malicious software that renders control to the Botnet operator.

Cyber criminals generate revenue from Botnets in much the same way as cloud computing providers like Amazon, Google, or Rackspace.  The Botnet operator sells the computational capacity of the Botnet for revenue-generating activities.  These activities can themselves range from the legal to the illegal including sending spam email, mining bitcoins, or generating fraudulant ad click throughs.

#### Command and Control

A Botnet operator must maintain command and control of the Botnet to further their criminal activities.  Typically, each Bot will "phone home" to a Command and Control server on a periodic basis to request the next set of commands.  The necessity for command and control serves as a weak point that can be exploited by those attempting to take down Botnets.  Identifying the means through which a Bot communicates with a Command and Control server can be used to identify and repair individual Bots, revoke control from the Botnet operator, or to identify and apprehend the Botnet operator.

#### Domain Generating Algorithms

Early Botnets simply contained a fixed list of domain names that were used by the Bot to contact a Command and Control server.  For example, each day the Bot would attempt to contact **bot-commander-1.com** and **bot-commander-2.com** for updated commands.  By monitoring network traffic patterns, it was simple to identify and block this fixed list of command and control servers, which rendered the Botnet useless.

Botnet operators evolved Domain Generating Algorithms (DGA) that automatically generate a large list of domain names through which to contact Command and Control servers.  Seeded cryptographic algorithms, similar to security tokens such as the RSA SecurID, enable the Botnet operator, and not those wishing to take down Botnets, to know with some degree of certainty which domains a Bot will use and at which time.  This mechanism makes it difficult to identify and disrupt access to Botnet Command and Control servers.  

This is but one approach among many that are collectively called "Command & Control Discovery Mechanisms."  More advanced approaches will continue to evolve to avoid detection including those that leverage P2P networks or The Onion Router (Tor).

#### DGA Classifier

This project contains a rudimentary classifier that can determine if a domain is legitimate or if it has been generated by a DGA.  Monitoring network traffic with a DGA Classifier enables defenders to identify and remediate Bots before significant damage can be caused.  For example, a computer requesting **ibxaoddvcped.ru** is much more indicative of a Bot versus one requesting **facebook.com**.

### Approach

### Additional Software

#### Aspell

Aspell provides an R interface to an English language dictionary.  Follow these steps to install Aspell.

1. Install the native Aspell library for your host environment.  

  * For Mac, use [Homebrew](http://brew.sh) by executng `brew install aspell` in a terminal.  

  * For Windows, download and execute the full [installer](http://aspell.net/win32/).

  * For a Linux distribution like Ubuntu with 'apt-get' execute `sudo apt-get install aspell aspell-en libaspell-dev'.

2. Ensure that you have the R developer tools installed.  The next step will require building a package from source which cannot be done without these.  (TODO: Find good, informative links on how to do this.)

3. Install the R package which provides an interface to the Aspell native library.  Simply run the following command within an R session.  

```
install.packages("Aspell", repos = "http://www.omegahat.org/R", type = "source")
```





====================== GIT HISTORY: ======================
0699fe7 HEAD@{0}: clone: from https://github.com/nickwallen/botnet-dga-classifier
commit 0699fe74bc12839cb9c84d634b8b4a34fa81a0b9
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Nov 20 13:09:10 2014 -0500

    Added files to ignore

commit b9e1e81326d515b41c0b87b92eb9e9b11e02457e
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Nov 20 13:08:44 2014 -0500

    Modified the download process to only use curl when it is installed.  Curl is required when downloading files through HTTPS on a Mac.

commit 97d56b91149a11ce020b1c49ac83a8029c73690f
Author: Nick Allen <nick@nickallen.org>
Date:   Fri Oct 24 16:53:48 2014 -0400

    For Issue #9 fixed-up some of the plots and removed the older code that was doing the ROC analysis.

commit 7a7514718d9956fed77aa75f58884529c537f959
Author: Nick Allen <nick@nickallen.org>
Date:   Fri Oct 24 16:31:38 2014 -0400

    For issue #9 determining the cutoff based on the training data and applying that cutoff on the model's final confidence/probability output.  There is not a significant improvement in doing this.

commit 478adad8d0a81c697cceafdadc862cd1605c62d8
Author: Nick Allen <nick@nickallen.org>
Date:   Fri Oct 24 15:56:48 2014 -0400

    For issue #9 Used a ROC curve to select a better probability cut-off.  I used the test data in this first pass (which is an incorrect way of doing it) that resulted in a boost in sensitivity from 9% to 75%. Need to do this as part of the training step next.

commit ed922b3da6b4ecb7633f392ce84eb2f13e11b8c0
Author: Nick Allen <nick@nickallen.org>
Date:   Fri Oct 24 15:16:54 2014 -0400

    Adding some additional diagnostics including the model confidence level to the markdown.

commit bd692abb33e151b4fedcc00ea40350bc626b9de1
Author: Nick Allen <nick@nickallen.org>
Date:   Fri Oct 24 12:51:08 2014 -0400

    Updating documentation on how to install Aspell.

commit fc08332beb7ebc55422d0e06d792f036d40f2aa1
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Oct 23 22:10:53 2014 -0400

    Additional instructions for installing Aspell.  Hope this works?

commit 2fd27302fa2fe7287f99e67b741b5956f0b30f21
Author: Nick Allen <nick@nickallen.org>
Date:   Sat Oct 18 10:44:29 2014 -0400

    Added the "not in" operator which just makes life simpler.

commit 25364b1458ea2b7e8f7796bcf61941111a9dd674
Author: Nick Allen <nick@nickallen.org>
Date:   Sat Oct 18 07:31:40 2014 -0400

    For Issue #6, centering and scaling all data along with adding some additional parameters for classification diagnostics

commit ce683952697ed1da8922a5923aa0c32c009fadaa
Author: Nick Allen <nick@nickallen.org>
Date:   Sat Oct 18 07:30:11 2014 -0400

    Added some additional diagnostics

commit 6f7dfd3e6dcc1734ba39e02d27066d44bec8dcbd
Author: Nick Allen <nick@nickallen.org>
Date:   Fri Oct 17 21:52:52 2014 -0400

    The 'malicious' class was not identified as the 'positive' class which is useful for interpreting the output.

commit 5a0e0dcc274d392d22ebd02f615b9625b4345c90
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Oct 16 20:43:52 2014 -0400

    Adding the resulting HTML files so they can be viewed directly by anyone through Github.

commit 086fa3174a9daa43b1df2b9f9c2555f5160ddbce
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Oct 16 20:41:55 2014 -0400

    Hiding output from the training process.

commit 9c0e824580ef36f056462ed4049f5903fbc5372b
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 15 18:49:38 2014 -0400

    Better description

commit 29f381150908ea78b4780e08449e07d779e0e16f
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 15 18:49:13 2014 -0400

    Adding additional required libraries.

commit 3e28bb5508825883323ae9bfa63543b4e4856517
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 15 18:48:49 2014 -0400

    The number of folds/iterations can now be specified as an argument to the function instead of accepting the default.

commit 2fe302838ea9ebec1590ab0d4740a45cb1125303
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 15 12:40:28 2014 -0400

    For issue #5 Added two methods to test the classification accuracy.  One is theoretical with a random hold-out set and the other is real-world as if new malware is released into the wild.

commit 3bea756b5cf30470954e966a444d7ebfd99b1f9e
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 15 08:52:20 2014 -0400

    Adding some additional analysis of the Dictionary Word Count feature among other formatting changes.

commit b0bc0e03938dcaf6f453f7d60ca5286180885638
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 15 08:36:45 2014 -0400

    Extracted expect_close function into the lib/ folder

commit c24b421387d8adfa644e6729ccaef37f1f506db5
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 15 08:35:55 2014 -0400

    Removed unneccessary test.

commit 22a5f05d37f7fbf29ae19da91fbc5b531d432fd3
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 15 08:35:15 2014 -0400

    Renamed count_dictionary_substrings to simply dictionary_words, for simplicity and the fact that dictionary words are no longer counted, but expressed as the fraction of all substrings that are dictionary words.

commit 681bfb3e98f2abdbbc600d3509b576bc13b0982a
Author: Nick Allen <nick@nickallen.org>
Date:   Tue Oct 14 23:06:01 2014 -0400

    Progress on issue #4.  The function returns the total number of prisoners versus those officially balloted at the prison.

commit 362697dee37579faa45680cd9576ad83511f3c95
Author: Nick Allen <nick@nickallen.org>
Date:   Tue Oct 14 22:32:22 2014 -0400

    Exploring the dictionary word count feature for Issue #1.

commit 9289375fa6288cc87d72d8621172aac6baacbf68
Author: Nick Allen <nick@nickallen.org>
Date:   Tue Oct 14 21:47:10 2014 -0400

    Improving the performance of checking dictionary workd for Issue #1.  Profiling showed that 95% of the time was in generating the substrings, not in doing the spell checking.  Using sapply over foreach with %dopar% is way, way faster.

commit ed91c194f43f0d6431da29238a197facc268af26
Author: Nick Allen <nick@nickallen.org>
Date:   Tue Oct 14 18:02:08 2014 -0400

    Dictionary count for Issue #1 fully working and passing all tests.

commit 84d8b8e998357ef0b98e300f3c6c746e5100ec81
Author: Nick Allen <nick@nickallen.org>
Date:   Tue Oct 14 18:01:31 2014 -0400

    The function is not vectorized (although that might make it quicker).  Adding a sanity check to ensure that its used correctly.

commit 7a61c8fc4a718f36468dde99e34d87789b4cd624
Author: Nick Allen <nick@nickallen.org>
Date:   Tue Oct 14 17:57:47 2014 -0400

    Initializing the parallel package (doMC) if it is installed on the host

commit 107254325aff7dbd99fe7b7637676f6714919b02
Author: Nick Allen <nick@nickallen.org>
Date:   Tue Oct 14 13:02:00 2014 -0400

    First pass at counting dictionary substrings for issue #1.  Performance is probably going to need some focus.

commit 761b066f7c9934eb81674b0218695940ec78caa0
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Oct 9 17:41:38 2014 -0400

    There are very few invalid domains to exclude.  No longer needed.

commit 07974ab7b3dc4996cf627009f0a0229c1acdef99
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Oct 9 17:41:17 2014 -0400

    Ignoring any intermediate markdown files.

commit 8ed7c6dda972161bb2fb5882d21a54784f846d76
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Oct 9 17:39:56 2014 -0400

    Adding the malicious domain data from Cryptolocker, Goz, and Newgoz that was captured from the Data Driven Security blog.

commit 50e2de91eada01ecc96167673e1909796001ee1a
Author: Nick Allen <nick@nickallen.org>
Date:   Thu Oct 9 17:38:41 2014 -0400

    The length of the domain name itself is likely to be an important differentiator between malicious and benign domain names.  The average malicious domain is about twice as long as the benign one; 21.5 characters for malicious domains versus 11.0 for legit domains. This should be useful for modeling. Closes issue #2.

commit 626f3a7104c353436195cd5a8115da374c88f166
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 8 13:15:23 2014 -0400

    Fixing my poor, poor grammar.

commit a778d3f9007d5d8b5c0b93a32898a7df4115b51f
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 8 13:14:15 2014 -0400

    Updated the title to match the repo name.

commit a855335ab942148743d18a5a86f7241a16d6e1e0
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 8 13:12:18 2014 -0400

    Removing the intermediary data sets after the 'domains' data set has been created

commit 1c9bf50f143a41bd65bacd0ac9ddb7f22c5f8edf
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 8 13:11:36 2014 -0400

    Added information on how to get started quickly with the project code.

commit 89f7b42101bd31ddd58a21db9e670bf3848b90da
Author: Nick Allen <nick@nickallen.org>
Date:   Wed Oct 8 12:49:50 2014 -0400

    Initial import of project sources.
